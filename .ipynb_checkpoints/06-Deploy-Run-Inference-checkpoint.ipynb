{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4 : Deploy, Run Inference, Interpret Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='overview-4'></a>\n",
    "\n",
    "## [Overview](./0-AutoClaimFraudDetection.ipynb)\n",
    "* [Notebook 0 : Overview, Architecture and Data Exploration](./0-AutoClaimFraudDetection.ipynb)\n",
    "* [Notebook 1: Data Prep, Process, Store Features](./1-data-prep-e2e.ipynb)\n",
    "* [Notebook 2: Train, Check Bias, Tune, Record Lineage, and Register a Model](./2-lineage-train-assess-bias-tune-registry-e2e.ipynb)\n",
    "* [Notebook 3: Mitigate Bias, Train New Model, Store in Registry](./3-mitigate-bias-train-model2-registry-e2e.ipynb)\n",
    "* **[Notebook 4: Deploy Model, Run Predictions](./4-deploy-run-inference-e2e.ipynb)**\n",
    "  * **[Architecture](#deploy)**\n",
    "  * **[Deploy an approved model and Run Inference via Feature Store](#deploy-model)**\n",
    "  * **[Create a Predictor](#predictor)**\n",
    "  * **[Run Predictions from Online FeatureStore](#run-predictions)**\n",
    "* [Notebook 5 : Create and Run an End-to-End Pipeline to Deploy the Model](./5-pipeline-e2e.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section of the end to end use case, we will deploy the mitigated model that is the end-product of this fraud detection use-case. We will show how to run inference and also how to use Clarify to interpret or \"explain\" the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install required and/or update third-party libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m pip install -Uq pip\n",
    "!python -m pip install -q awswrangler==2.2.0 imbalanced-learn==0.7.0 sagemaker==2.41.0 boto3==1.17.70"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load stored variables\n",
    "Run the cell below to load any prevously created variables. You should see a print-out of the existing variables. If you don't see anything you may need to create them again or it may be your first time running this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored variables and their in-db values:\n",
      "bucket                              -> 'sagemaker-us-east-1-875692608981'\n",
      "claims_fg_name                      -> 'fraud-detect-demo-claims'\n",
      "claims_table                        -> 'fraud-detect-demo-claims-1635991472'\n",
      "clarify_bias_job_1_name             -> 'Clarify-Bias-2021-11-04-02-57-18-432'\n",
      "clarify_bias_job_2_name             -> 'Clarify-Bias-2021-11-04-03-30-25-420'\n",
      "clarify_expl_job_name               -> 'Clarify-Explainability-2021-11-04-03-43-09-860'\n",
      "col_order                           -> ['fraud', 'incident_type_breakin', 'num_vehicles_i\n",
      "customers_fg_name                   -> 'fraud-detect-demo-customers'\n",
      "customers_table                     -> 'fraud-detect-demo-customers-1635991475'\n",
      "database_name                       -> 'sagemaker_featurestore'\n",
      "hyperparameters                     -> {'max_depth': '3', 'eta': '0.2', 'objective': 'bin\n",
      "model_1_name                        -> 'fraud-detect-demo-xgboost-pre-smote'\n",
      "model_2_name                        -> 'fraud-detect-demo-xgboost-post-smote'\n",
      "mp2_arn                             -> 'arn:aws:sagemaker:us-east-1:875692608981:model-pa\n",
      "mpg_name                            -> 'fraud-detect-demo'\n",
      "prefix                              -> 'fraud-detect-demo'\n",
      "test_data_uri                       -> 's3://sagemaker-us-east-1-875692608981/fraud-detec\n",
      "train_data_uri                      -> 's3://sagemaker-us-east-1-875692608981/fraud-detec\n",
      "training_job_1_name                 -> 'sagemaker-xgboost-2021-11-04-02-25-54-586'\n",
      "training_job_2_name                 -> 'sagemaker-xgboost-2021-11-04-03-23-44-035'\n"
     ]
    }
   ],
   "source": [
    "%store -r\n",
    "%store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color='red'>Important</font>: You must have run the previous sequential notebooks to retrieve variables using the StoreMagic command.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "import boto3\n",
    "import sagemaker\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import awswrangler as wr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set region, boto3 and SageMaker SDK variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using AWS Region: us-east-1\n"
     ]
    }
   ],
   "source": [
    "# You can change this to a region of your choice\n",
    "import sagemaker\n",
    "\n",
    "region = sagemaker.Session().boto_region_name\n",
    "print(\"Using AWS Region: {}\".format(region))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "boto3.setup_default_session(region_name=region)\n",
    "\n",
    "boto_session = boto3.Session(region_name=region)\n",
    "\n",
    "s3_client = boto3.client(\"s3\", region_name=region)\n",
    "\n",
    "sagemaker_boto_client = boto_session.client(\"sagemaker\")\n",
    "\n",
    "sagemaker_session = sagemaker.session.Session(\n",
    "    boto_session=boto_session, sagemaker_client=sagemaker_boto_client\n",
    ")\n",
    "\n",
    "sagemaker_role = sagemaker.get_execution_role()\n",
    "\n",
    "account_id = boto3.client(\"sts\").get_caller_identity()[\"Account\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables used for parameterizing the notebook run\n",
    "endpoint_name = f\"{model_2_name}-endpoint\"\n",
    "endpoint_instance_count = 1\n",
    "endpoint_instance_type = \"ml.m4.xlarge\"\n",
    "\n",
    "predictor_instance_count = 1\n",
    "predictor_instance_type = \"ml.c5.xlarge\"\n",
    "batch_transform_instance_count = 1\n",
    "batch_transform_instance_type = \"ml.c5.xlarge\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id ='deploy'> </a>\n",
    "\n",
    "## Architecture for this ML Lifecycle Stage : Train, Check Bias, Tune, Record Lineage, Register Model\n",
    "[overview](#overview-4)\n",
    "\n",
    "![train-assess-tune-register](./images/e2e-3-pipeline-v3b.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id ='deploy-model'></a>\n",
    "\n",
    "## Deploy an approved model and make prediction via Feature Store\n",
    "\n",
    "[overview](#overview-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Approve the second model\n",
    "In the real-life MLOps lifecycle, a model package gets approved after evaluation by data scientists, subject matter experts and auditors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_model_package = sagemaker_boto_client.list_model_packages(ModelPackageGroupName=mpg_name)[\n",
    "    \"ModelPackageSummaryList\"\n",
    "][0]\n",
    "model_package_update = {\n",
    "    \"ModelPackageArn\": second_model_package[\"ModelPackageArn\"],\n",
    "    \"ModelApprovalStatus\": \"Approved\",\n",
    "}\n",
    "\n",
    "update_response = sagemaker_boto_client.update_model_package(**model_package_update)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create an endpoint config and an endpoint\n",
    "Deploy the endpoint. This might take about 8minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'endpoint_config_name' (str)\n"
     ]
    }
   ],
   "source": [
    "primary_container = {'ModelPackageName': second_model_package['ModelPackageArn']}\n",
    "endpoint_config_name=f'{model_2_name}-endpoint-config'\n",
    "existing_configs = len(sagemaker_boto_client.list_endpoint_configs(NameContains=endpoint_config_name, MaxResults = 30)['EndpointConfigs'])\n",
    "\n",
    "if existing_configs == 0:\n",
    "    create_ep_config_response = sagemaker_boto_client.create_endpoint_config(\n",
    "        EndpointConfigName=endpoint_config_name,\n",
    "        ProductionVariants=[{\n",
    "            'InstanceType': endpoint_instance_type,\n",
    "            'InitialVariantWeight': 1,\n",
    "            'InitialInstanceCount': endpoint_instance_count,\n",
    "            'ModelName': model_2_name,\n",
    "            'VariantName': 'AllTraffic'\n",
    "        }]\n",
    "    )\n",
    "    %store endpoint_config_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'endpoint_name' (str)\n",
      "Endpoint status: Creating\n",
      "Endpoint status: Creating\n",
      "Endpoint status: Creating\n",
      "Endpoint status: InService\n"
     ]
    }
   ],
   "source": [
    "existing_endpoints = sagemaker_boto_client.list_endpoints(NameContains=endpoint_name, MaxResults = 30)['Endpoints']\n",
    "if not existing_endpoints:\n",
    "    create_endpoint_response = sagemaker_boto_client.create_endpoint(\n",
    "        EndpointName=endpoint_name,\n",
    "        EndpointConfigName=endpoint_config_name)\n",
    "    %store endpoint_name\n",
    "\n",
    "endpoint_info = sagemaker_boto_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "endpoint_status = endpoint_info['EndpointStatus']\n",
    "\n",
    "while endpoint_status == 'Creating':\n",
    "    endpoint_info = sagemaker_boto_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "    endpoint_status = endpoint_info['EndpointStatus']\n",
    "    print('Endpoint status:', endpoint_status)\n",
    "    if endpoint_status == 'Creating':\n",
    "        time.sleep(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='predictor'> </a>\n",
    "\n",
    "### Create a predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = sagemaker.predictor.Predictor(\n",
    "    endpoint_name=endpoint_name, sagemaker_session=sagemaker_session\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample a claim from the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"data/dataset.csv\")\n",
    "train = dataset.sample(frac=0.8, random_state=0)\n",
    "test = dataset.drop(train.index)\n",
    "sample_policy_id = int(test.sample(1)[\"policy_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1000 entries, 0 to 4997\n",
      "Data columns (total 48 columns):\n",
      " #   Column                           Non-Null Count  Dtype  \n",
      "---  ------                           --------------  -----  \n",
      " 0   Unnamed: 0                       1000 non-null   int64  \n",
      " 1   policy_id                        1000 non-null   int64  \n",
      " 2   incident_type_breakin            1000 non-null   int64  \n",
      " 3   num_vehicles_involved            1000 non-null   int64  \n",
      " 4   collision_type_na                1000 non-null   int64  \n",
      " 5   policy_state_nv                  1000 non-null   int64  \n",
      " 6   authorities_contacted_fire       1000 non-null   int64  \n",
      " 7   customer_gender_male             1000 non-null   int64  \n",
      " 8   authorities_contacted_ambulance  1000 non-null   int64  \n",
      " 9   injury_claim                     1000 non-null   float64\n",
      " 10  policy_deductable                1000 non-null   int64  \n",
      " 11  collision_type_front             1000 non-null   int64  \n",
      " 12  authorities_contacted_none       1000 non-null   int64  \n",
      " 13  driver_relationship_self         1000 non-null   int64  \n",
      " 14  fraud                            1000 non-null   int64  \n",
      " 15  collision_type_rear              1000 non-null   int64  \n",
      " 16  policy_state_or                  1000 non-null   int64  \n",
      " 17  driver_relationship_spouse       1000 non-null   int64  \n",
      " 18  auto_year                        1000 non-null   int64  \n",
      " 19  num_witnesses                    1000 non-null   int64  \n",
      " 20  incident_month                   1000 non-null   int64  \n",
      " 21  vehicle_claim                    1000 non-null   float64\n",
      " 22  incident_hour                    1000 non-null   int64  \n",
      " 23  num_claims_past_year             1000 non-null   int64  \n",
      " 24  driver_relationship_other        1000 non-null   int64  \n",
      " 25  authorities_contacted_police     1000 non-null   int64  \n",
      " 26  driver_relationship_na           1000 non-null   int64  \n",
      " 27  incident_day                     1000 non-null   int64  \n",
      " 28  incident_type_theft              1000 non-null   int64  \n",
      " 29  policy_state_az                  1000 non-null   int64  \n",
      " 30  customer_gender_female           1000 non-null   int64  \n",
      " 31  policy_annual_premium            1000 non-null   int64  \n",
      " 32  months_as_customer               1000 non-null   int64  \n",
      " 33  policy_state_ca                  1000 non-null   int64  \n",
      " 34  num_insurers_past_5_years        1000 non-null   int64  \n",
      " 35  total_claim_amount               1000 non-null   float64\n",
      " 36  incident_dow                     1000 non-null   int64  \n",
      " 37  incident_type_collision          1000 non-null   int64  \n",
      " 38  customer_age                     1000 non-null   int64  \n",
      " 39  collision_type_side              1000 non-null   int64  \n",
      " 40  driver_relationship_child        1000 non-null   int64  \n",
      " 41  police_report_available          1000 non-null   int64  \n",
      " 42  policy_state_wa                  1000 non-null   int64  \n",
      " 43  incident_severity                1000 non-null   int64  \n",
      " 44  customer_education               1000 non-null   int64  \n",
      " 45  policy_liability                 1000 non-null   int64  \n",
      " 46  policy_state_id                  1000 non-null   int64  \n",
      " 47  num_injuries                     1000 non-null   int64  \n",
      "dtypes: float64(3), int64(45)\n",
      "memory usage: 382.8 KB\n"
     ]
    }
   ],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get sample's claim data from online feature store\n",
    "This will simulate getting data in real-time from a customer's insurance claim submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "featurestore_runtime = boto_session.client(\n",
    "    service_name=\"sagemaker-featurestore-runtime\", region_name=region\n",
    ")\n",
    "\n",
    "feature_store_session = sagemaker.Session(\n",
    "    boto_session=boto_session,\n",
    "    sagemaker_client=sagemaker_boto_client,\n",
    "    sagemaker_featurestore_runtime_client=featurestore_runtime,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='run-predictions'> </a>\n",
    "\n",
    "## Run Predictions on Multiple Claims\n",
    "\n",
    "[overview](#overview-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probablitity the claim from policy 3740 is fraudulent: 0.12106682360172272\n",
      "Probablitity the claim from policy 2667 is fraudulent: 0.005608935374766588\n",
      "Probablitity the claim from policy 801 is fraudulent: 0.013018963858485222\n",
      "Probablitity the claim from policy 4478 is fraudulent: 0.020848188549280167\n",
      "Probablitity the claim from policy 275 is fraudulent: 0.013813871890306473\n",
      "Probablitity the claim from policy 3836 is fraudulent: 0.010482619516551495\n",
      "Probablitity the claim from policy 2791 is fraudulent: 0.007228601723909378\n",
      "Probablitity the claim from policy 1955 is fraudulent: 0.11650000512599945\n",
      "Probablitity the claim from policy 2667 is fraudulent: 0.005608935374766588\n",
      "Probablitity the claim from policy 2954 is fraudulent: 0.003533664159476757\n",
      "Probablitity the claim from policy 4042 is fraudulent: 0.37386268377304077\n",
      "Probablitity the claim from policy 3237 is fraudulent: 0.007228601723909378\n",
      "Probablitity the claim from policy 1808 is fraudulent: 0.01955937035381794\n",
      "Probablitity the claim from policy 1585 is fraudulent: 0.006191974971443415\n",
      "Probablitity the claim from policy 4487 is fraudulent: 0.0025501977652311325\n",
      "Probablitity the claim from policy 2326 is fraudulent: 0.005983139853924513\n",
      "Probablitity the claim from policy 776 is fraudulent: 0.01096257008612156\n",
      "Probablitity the claim from policy 752 is fraudulent: 0.023869039490818977\n",
      "Probablitity the claim from policy 4136 is fraudulent: 0.029256606474518776\n",
      "Probablitity the claim from policy 2034 is fraudulent: 0.00399095518514514\n",
      "Probablitity the claim from policy 4511 is fraudulent: 0.019704200327396393\n",
      "Probablitity the claim from policy 538 is fraudulent: 0.009426907636225224\n",
      "Probablitity the claim from policy 3628 is fraudulent: 0.0038606117013841867\n",
      "Probablitity the claim from policy 4042 is fraudulent: 0.37386268377304077\n",
      "Probablitity the claim from policy 840 is fraudulent: 0.0038038596976548433\n",
      "Probablitity the claim from policy 3970 is fraudulent: 0.0027738765347748995\n",
      "Probablitity the claim from policy 3992 is fraudulent: 0.014695781283080578\n",
      "Probablitity the claim from policy 2846 is fraudulent: 0.003064019838348031\n",
      "Probablitity the claim from policy 2222 is fraudulent: 0.025660792365670204\n",
      "Probablitity the claim from policy 538 is fraudulent: 0.009426907636225224\n",
      "Probablitity the claim from policy 4586 is fraudulent: 0.034597888588905334\n",
      "Probablitity the claim from policy 2637 is fraudulent: 0.025660792365670204\n",
      "Probablitity the claim from policy 3099 is fraudulent: 0.03167526796460152\n",
      "Probablitity the claim from policy 162 is fraudulent: 0.004234393127262592\n",
      "Probablitity the claim from policy 4080 is fraudulent: 0.016042344272136688\n",
      "Probablitity the claim from policy 1234 is fraudulent: 0.011266907677054405\n",
      "Probablitity the claim from policy 4584 is fraudulent: 0.004810186568647623\n",
      "Probablitity the claim from policy 734 is fraudulent: 0.002531976904720068\n",
      "Probablitity the claim from policy 3928 is fraudulent: 0.008528478443622589\n",
      "Probablitity the claim from policy 502 is fraudulent: 0.01955937035381794\n",
      "Probablitity the claim from policy 3875 is fraudulent: 0.02454560250043869\n",
      "Probablitity the claim from policy 279 is fraudulent: 0.008707700297236443\n",
      "Probablitity the claim from policy 1648 is fraudulent: 0.006765174213796854\n",
      "Probablitity the claim from policy 1458 is fraudulent: 0.005578216165304184\n",
      "Probablitity the claim from policy 2973 is fraudulent: 0.005515960976481438\n",
      "Probablitity the claim from policy 1141 is fraudulent: 0.003986278083175421\n",
      "Probablitity the claim from policy 3963 is fraudulent: 0.004883931949734688\n",
      "Probablitity the claim from policy 538 is fraudulent: 0.009426907636225224\n",
      "Probablitity the claim from policy 4007 is fraudulent: 0.01074222382158041\n",
      "Probablitity the claim from policy 3290 is fraudulent: 0.003533664159476757\n",
      "Probablitity the claim from policy 533 is fraudulent: 0.021678948774933815\n",
      "Probablitity the claim from policy 752 is fraudulent: 0.023869039490818977\n",
      "Probablitity the claim from policy 3679 is fraudulent: 0.002088506007567048\n",
      "Probablitity the claim from policy 2166 is fraudulent: 0.016885045915842056\n",
      "Probablitity the claim from policy 1930 is fraudulent: 0.007008024957031012\n",
      "Probablitity the claim from policy 1786 is fraudulent: 0.025660792365670204\n",
      "Probablitity the claim from policy 2606 is fraudulent: 0.007980728521943092\n",
      "Probablitity the claim from policy 2000 is fraudulent: 0.0032430088613182306\n",
      "Probablitity the claim from policy 1266 is fraudulent: 0.03866208344697952\n",
      "Probablitity the claim from policy 752 is fraudulent: 0.023869039490818977\n",
      "Probablitity the claim from policy 2582 is fraudulent: 0.006005397532135248\n",
      "Probablitity the claim from policy 2674 is fraudulent: 0.07112588733434677\n",
      "Probablitity the claim from policy 2912 is fraudulent: 0.00241393712349236\n",
      "Probablitity the claim from policy 590 is fraudulent: 0.007041722536087036\n",
      "Probablitity the claim from policy 3041 is fraudulent: 0.0041726017370820045\n",
      "Probablitity the claim from policy 2771 is fraudulent: 0.008000246249139309\n",
      "Probablitity the claim from policy 1568 is fraudulent: 0.07264075428247452\n",
      "Probablitity the claim from policy 2555 is fraudulent: 0.00786489900201559\n",
      "Probablitity the claim from policy 4475 is fraudulent: 0.005279410630464554\n",
      "Probablitity the claim from policy 1470 is fraudulent: 0.0440080389380455\n",
      "Probablitity the claim from policy 4464 is fraudulent: 0.04132942855358124\n",
      "Probablitity the claim from policy 1155 is fraudulent: 0.0034701544791460037\n",
      "Probablitity the claim from policy 1465 is fraudulent: 0.022418387234210968\n",
      "Probablitity the claim from policy 1585 is fraudulent: 0.006191974971443415\n",
      "Probablitity the claim from policy 1868 is fraudulent: 0.00457529304549098\n",
      "Probablitity the claim from policy 4573 is fraudulent: 0.005200580693781376\n",
      "Probablitity the claim from policy 1384 is fraudulent: 0.007662603165954351\n",
      "Probablitity the claim from policy 2260 is fraudulent: 0.3043500781059265\n",
      "Probablitity the claim from policy 3305 is fraudulent: 0.00932267028838396\n",
      "Probablitity the claim from policy 4411 is fraudulent: 0.004216350615024567\n",
      "Probablitity the claim from policy 3017 is fraudulent: 0.003184319008141756\n",
      "Probablitity the claim from policy 3571 is fraudulent: 0.020481646060943604\n",
      "Probablitity the claim from policy 1930 is fraudulent: 0.007008024957031012\n",
      "Probablitity the claim from policy 4071 is fraudulent: 0.04734860733151436\n",
      "Probablitity the claim from policy 4319 is fraudulent: 0.04764920100569725\n",
      "Probablitity the claim from policy 755 is fraudulent: 0.013773583807051182\n",
      "Probablitity the claim from policy 4148 is fraudulent: 0.01254106406122446\n",
      "Probablitity the claim from policy 590 is fraudulent: 0.007041722536087036\n",
      "Probablitity the claim from policy 1924 is fraudulent: 0.015680979937314987\n",
      "Probablitity the claim from policy 3582 is fraudulent: 0.007433332037180662\n",
      "Probablitity the claim from policy 882 is fraudulent: 0.0029203102458268404\n",
      "Probablitity the claim from policy 2689 is fraudulent: 0.0027738765347748995\n",
      "Probablitity the claim from policy 3679 is fraudulent: 0.002088506007567048\n",
      "Probablitity the claim from policy 795 is fraudulent: 0.023869039490818977\n",
      "Probablitity the claim from policy 1416 is fraudulent: 0.007530073635280132\n",
      "Probablitity the claim from policy 1999 is fraudulent: 0.010100599378347397\n",
      "Probablitity the claim from policy 2648 is fraudulent: 0.009460254572331905\n",
      "Probablitity the claim from policy 3730 is fraudulent: 0.0026789922267198563\n",
      "Probablitity the claim from policy 4136 is fraudulent: 0.029256606474518776\n",
      "Probablitity the claim from policy 4962 is fraudulent: 0.01727212592959404\n"
     ]
    }
   ],
   "source": [
    "import datetime as datetime\n",
    "\n",
    "timer = []\n",
    "MAXRECS = 100\n",
    "\n",
    "\n",
    "def barrage_of_inference():\n",
    "    sample_policy_id = int(test.sample(1)[\"policy_id\"])\n",
    "\n",
    "    temp_fg_name = \"fraud-detect-demo-claims\"\n",
    "\n",
    "    claims_response = featurestore_runtime.get_record(\n",
    "        FeatureGroupName=temp_fg_name, RecordIdentifierValueAsString=str(sample_policy_id)\n",
    "    )\n",
    "\n",
    "    if claims_response.get(\"Record\"):\n",
    "        claims_record = claims_response[\"Record\"]\n",
    "        claims_df = pd.DataFrame(claims_record).set_index(\"FeatureName\")\n",
    "    else:\n",
    "        print(\"No Record returned / Record Key  \\n\")\n",
    "\n",
    "    t0 = datetime.datetime.now()\n",
    "\n",
    "    customers_response = featurestore_runtime.get_record(\n",
    "        FeatureGroupName=customers_fg_name, RecordIdentifierValueAsString=str(sample_policy_id)\n",
    "    )\n",
    "\n",
    "    t1 = datetime.datetime.now()\n",
    "\n",
    "    customer_record = customers_response[\"Record\"]\n",
    "    customer_df = pd.DataFrame(customer_record).set_index(\"FeatureName\")\n",
    "\n",
    "    blended_df = pd.concat([claims_df, customer_df]).loc[col_order].drop(\"fraud\")\n",
    "    data_input = \",\".join(blended_df[\"ValueAsString\"])\n",
    "\n",
    "    results = predictor.predict(data_input, initial_args={\"ContentType\": \"text/csv\"})\n",
    "    prediction = json.loads(results)\n",
    "    # print (f'Probablitity the claim from policy {int(sample_policy_id)} is fraudulent:', prediction)\n",
    "\n",
    "    arr = t1 - t0\n",
    "    minutes, seconds = divmod(arr.total_seconds(), 60)\n",
    "\n",
    "    timer.append(seconds)\n",
    "    # print (prediction, \" done in {} \".format(seconds))\n",
    "\n",
    "    return sample_policy_id, prediction\n",
    "\n",
    "\n",
    "for i in range(MAXRECS):\n",
    "    sample_policy_id, prediction = barrage_of_inference()\n",
    "    print(f\"Probablitity the claim from policy {int(sample_policy_id)} is fraudulent:\", prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.059719,\n",
       " 0.009545,\n",
       " 0.013062,\n",
       " 0.012054,\n",
       " 0.014059,\n",
       " 0.009755,\n",
       " 0.010177,\n",
       " 0.011736,\n",
       " 0.010717,\n",
       " 0.012913,\n",
       " 0.01318,\n",
       " 0.009719,\n",
       " 0.010391,\n",
       " 0.010631,\n",
       " 0.011139,\n",
       " 0.010635,\n",
       " 0.009286,\n",
       " 0.010314,\n",
       " 0.008947,\n",
       " 0.009487,\n",
       " 0.009279,\n",
       " 0.008239,\n",
       " 0.008908,\n",
       " 0.00879,\n",
       " 0.00986,\n",
       " 0.009515,\n",
       " 0.009892,\n",
       " 0.008619,\n",
       " 0.008853,\n",
       " 0.00829,\n",
       " 0.009192,\n",
       " 0.009973,\n",
       " 0.009538,\n",
       " 0.01034,\n",
       " 0.009005,\n",
       " 0.008588,\n",
       " 0.010041,\n",
       " 0.008806,\n",
       " 0.008841,\n",
       " 0.010646,\n",
       " 0.010396,\n",
       " 0.009049,\n",
       " 0.009247,\n",
       " 0.008071,\n",
       " 0.008042,\n",
       " 0.011088,\n",
       " 0.008095,\n",
       " 0.008471,\n",
       " 0.010173,\n",
       " 0.008392,\n",
       " 0.008582,\n",
       " 0.008739,\n",
       " 0.008754,\n",
       " 0.008282,\n",
       " 0.009852,\n",
       " 0.0131,\n",
       " 0.008456,\n",
       " 0.00965,\n",
       " 0.008407,\n",
       " 0.01043,\n",
       " 0.009084,\n",
       " 0.008627,\n",
       " 0.008486,\n",
       " 0.009835,\n",
       " 0.009006,\n",
       " 0.008949,\n",
       " 0.010101,\n",
       " 0.008911,\n",
       " 0.010445,\n",
       " 0.008179,\n",
       " 0.014384,\n",
       " 0.009462,\n",
       " 0.008765,\n",
       " 0.020293,\n",
       " 0.009559,\n",
       " 0.009583,\n",
       " 0.007928,\n",
       " 0.008838,\n",
       " 0.008323,\n",
       " 0.013265,\n",
       " 0.008512,\n",
       " 0.00845,\n",
       " 0.00892,\n",
       " 0.010605,\n",
       " 0.010422,\n",
       " 0.009748,\n",
       " 0.008009,\n",
       " 0.008402,\n",
       " 0.00838,\n",
       " 0.008775,\n",
       " 0.008309,\n",
       " 0.008933,\n",
       " 0.00886,\n",
       " 0.008718,\n",
       " 0.010214,\n",
       " 0.008412,\n",
       " 0.008238,\n",
       " 0.008941,\n",
       " 0.009089,\n",
       " 0.009297]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: the above \"timer\" records the first call and then subsequent calls to the online Feature Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p95: 0.01318425, p99: 0.0206872600000002, mean: 0.010192139999999999 for 100 distinct feature store gets\n"
     ]
    }
   ],
   "source": [
    "import statistics\n",
    "import numpy as np\n",
    "\n",
    "statistics.mean(timer)\n",
    "\n",
    "\n",
    "arr = np.array(timer)\n",
    "print(\n",
    "    \"p95: {}, p99: {}, mean: {} for {} distinct feature store gets\".format(\n",
    "        np.percentile(arr, 95), np.percentile(arr, 99), np.mean(arr), MAXRECS\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pull customer data from Customers feature group\n",
    "When a customer submits an insurance claim online for instant approval, the insurance company will need to pull customer-specific data from the online feature store to add to the claim data as input for a model prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "customers_response = featurestore_runtime.get_record(\n",
    "    FeatureGroupName=customers_fg_name, RecordIdentifierValueAsString=str(sample_policy_id)\n",
    ")\n",
    "\n",
    "customer_record = customers_response[\"Record\"]\n",
    "customer_df = pd.DataFrame(customer_record).set_index(\"FeatureName\")\n",
    "\n",
    "\n",
    "claims_response = featurestore_runtime.get_record(\n",
    "    FeatureGroupName=claims_fg_name, RecordIdentifierValueAsString=str(sample_policy_id)\n",
    ")\n",
    "\n",
    "claims_record = claims_response[\"Record\"]\n",
    "claims_df = pd.DataFrame(claims_record).set_index(\"FeatureName\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Format the datapoint\n",
    "The datapoint must match the exact input format as the model was trained--with all features in the correct order. In this example, the `col_order` variable was saved when you created the train and test datasets earlier in the guide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "blended_df = pd.concat([claims_df, customer_df]).loc[col_order].drop(\"fraud\")\n",
    "data_input = \",\".join(blended_df[\"ValueAsString\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probablitity the claim from policy 4962 is fraudulent: 0.01727212592959404\n"
     ]
    }
   ],
   "source": [
    "results = predictor.predict(data_input, initial_args={\"ContentType\": \"text/csv\"})\n",
    "prediction = json.loads(results)\n",
    "print(f\"Probablitity the claim from policy {int(sample_policy_id)} is fraudulent:\", prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "<a id='aud-workflow-pipeline'></a>\n",
    "\n",
    "### Next Notebook: [Create and Run an End-to-End Pipeline to Deploy the Model](./07-Pipeline.ipynb)\n",
    "Now that as a Data Scientist, you've manually experimented with each step in our machine learning workflow, you can take certain steps to allow for faster model creation and deployment without sacrificing transparency and tracking via model lineage. In the next section you will create a pipeline which trains a new model on SageMaker, persists the model in SageMaker and then adds the model to the registry and deploys it as a SageMaker hosted endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
