{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4 : Deploy, Run Inference, Interpret Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='overview-4'></a>\n",
    "\n",
    "## [Overview](./0-AutoClaimFraudDetection.ipynb)\n",
    "* [Notebook 0 : Overview, Architecture and Data Exploration](./0-AutoClaimFraudDetection.ipynb)\n",
    "* [Notebook 1: Data Prep, Process, Store Features](./1-data-prep-e2e.ipynb)\n",
    "* [Notebook 2: Train, Check Bias, Tune, Record Lineage, and Register a Model](./2-lineage-train-assess-bias-tune-registry-e2e.ipynb)\n",
    "* [Notebook 3: Mitigate Bias, Train New Model, Store in Registry](./3-mitigate-bias-train-model2-registry-e2e.ipynb)\n",
    "* **[Notebook 4: Deploy Model, Run Predictions](./4-deploy-run-inference-e2e.ipynb)**\n",
    "  * **[Architecture](#deploy)**\n",
    "  * **[Deploy an approved model and Run Inference via Feature Store](#deploy-model)**\n",
    "  * **[Create a Predictor](#predictor)**\n",
    "  * **[Run Predictions from Online FeatureStore](#run-predictions)**\n",
    "* [Notebook 5 : Create and Run an End-to-End Pipeline to Deploy the Model](./5-pipeline-e2e.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section of the end to end use case, we will deploy the mitigated model that is the end-product of this fraud detection use-case. We will show how to run inference and also how to use Clarify to interpret or \"explain\" the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install required and/or update third-party libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m pip install -Uq pip\n",
    "!python -m pip install -q awswrangler imbalanced-learn sagemaker boto3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load stored variables\n",
    "Run the cell below to load any prevously created variables. You should see a print-out of the existing variables. If you don't see anything you may need to create them again or it may be your first time running this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored variables and their in-db values:\n",
      "bucket                              -> 'sagemaker-us-east-1-875692608981'\n",
      "claims_fg_name                      -> 'fraud-detect-demo-claims'\n",
      "claims_preprocessed                 ->       policy_id  incident_severity  num_vehicles_i\n",
      "claims_table                        -> 'fraud-detect-demo-claims-1637021687'\n",
      "clarify_bias_job_1_name             -> 'Clarify-Bias-2021-11-16-01-24-37-110'\n",
      "clarify_bias_job_2_name             -> 'Clarify-Bias-2021-11-16-02-36-07-707'\n",
      "clarify_expl_job_name               -> 'Clarify-Explainability-2021-11-16-02-48-36-081'\n",
      "col_order                           -> ['fraud', 'driver_relationship_spouse', 'num_insur\n",
      "customers_fg_name                   -> 'fraud-detect-demo-customers'\n",
      "customers_preprocessed              ->       policy_id  customer_age  customer_education \n",
      "customers_table                     -> 'fraud-detect-demo-customers-1637021688'\n",
      "database_name                       -> 'sagemaker_featurestore'\n",
      "dataset_uri                         -> 's3://sagemaker-us-east-1-875692608981/fraud-detec\n",
      "hyperparameters                     -> {'max_depth': '3', 'eta': '0.2', 'objective': 'bin\n",
      "model_1_name                        -> 'fraud-detect-demo-xgboost-pre-smote'\n",
      "model_2_name                        -> 'fraud-detect-demo-xgboost-post-smote'\n",
      "mp2_arn                             -> 'arn:aws:sagemaker:us-east-1:875692608981:model-pa\n",
      "mpg_name                            -> 'fraud-detect-demo'\n",
      "prefix                              -> 'fraud-detect-demo'\n",
      "test_data_uri                       -> 's3://sagemaker-us-east-1-875692608981/fraud-detec\n",
      "train                               ->       fraud  driver_relationship_spouse  num_insur\n",
      "train_data_uri                      -> 's3://sagemaker-us-east-1-875692608981/fraud-detec\n",
      "training_job_1_name                 -> 'sagemaker-xgboost-2021-11-16-00-32-53-939'\n",
      "training_job_2_name                 -> 'sagemaker-xgboost-2021-11-16-01-41-55-327'\n"
     ]
    }
   ],
   "source": [
    "%store -r\n",
    "%store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color='red'>Important</font>: You must have run the previous sequential notebooks to retrieve variables using the StoreMagic command.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "import boto3\n",
    "import sagemaker\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import awswrangler as wr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set region, boto3 and SageMaker SDK variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using AWS Region: us-east-1\n"
     ]
    }
   ],
   "source": [
    "# You can change this to a region of your choice\n",
    "region = sagemaker.Session().boto_region_name\n",
    "print(\"Using AWS Region: {}\".format(region))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "boto3.setup_default_session(region_name=region)\n",
    "\n",
    "boto_session = boto3.Session(region_name=region)\n",
    "\n",
    "s3_client = boto3.client(\"s3\", region_name=region)\n",
    "\n",
    "sagemaker_client = boto_session.client(\"sagemaker\")\n",
    "\n",
    "sagemaker_session = sagemaker.session.Session(\n",
    "    boto_session=boto_session, sagemaker_client=sagemaker_client\n",
    ")\n",
    "\n",
    "sagemaker_role = sagemaker.get_execution_role()\n",
    "\n",
    "account_id = boto3.client(\"sts\").get_caller_identity()[\"Account\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables used for parameterizing the notebook run\n",
    "endpoint_name = f\"{model_2_name}-endpoint\"\n",
    "endpoint_instance_count = 1\n",
    "endpoint_instance_type = \"ml.m4.xlarge\"\n",
    "\n",
    "predictor_instance_count = 1\n",
    "predictor_instance_type = \"ml.c5.xlarge\"\n",
    "batch_transform_instance_count = 1\n",
    "batch_transform_instance_type = \"ml.c5.xlarge\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id ='deploy'> </a>\n",
    "\n",
    "## Architecture for this ML Lifecycle Stage : Train, Check Bias, Tune, Record Lineage, Register Model\n",
    "[overview](#overview-4)\n",
    "\n",
    "![train-assess-tune-register](./images/e2e-3-pipeline-v3b.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id ='deploy-model'></a>\n",
    "\n",
    "## Deploy an approved model and make prediction via Feature Store\n",
    "\n",
    "[overview](#overview-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Approve the second model\n",
    "In the real-life MLOps lifecycle, a model package gets approved after evaluation by data scientists, subject matter experts and auditors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![train-assess-tune-register](./images/bestmodel.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ModelPackageGroupName': 'fraud-detect-demo',\n",
       " 'ModelPackageVersion': 2,\n",
       " 'ModelPackageArn': 'arn:aws:sagemaker:us-east-1:875692608981:model-package/fraud-detect-demo/2',\n",
       " 'ModelPackageDescription': 'XGBoost classifier to detect insurance fraud with SMOTE.',\n",
       " 'CreationTime': datetime.datetime(2021, 11, 16, 3, 6, 57, 593000, tzinfo=tzlocal()),\n",
       " 'ModelPackageStatus': 'Completed',\n",
       " 'ModelApprovalStatus': 'PendingManualApproval'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sagemaker_client.list_model_packages(ModelPackageGroupName=mpg_name)[\"ModelPackageSummaryList\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ModelPackageArn': 'arn:aws:sagemaker:us-east-1:875692608981:model-package/fraud-detect-demo/2',\n",
       " 'ResponseMetadata': {'RequestId': '268eaf65-3577-4263-a912-553025d6a587',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '268eaf65-3577-4263-a912-553025d6a587',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '96',\n",
       "   'date': 'Tue, 16 Nov 2021 03:09:14 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_model_package = sagemaker_client.list_model_packages(ModelPackageGroupName=mpg_name)[\"ModelPackageSummaryList\"][0]\n",
    "model_package_update = {\n",
    "    \"ModelPackageArn\": second_model_package[\"ModelPackageArn\"],\n",
    "    \"ModelApprovalStatus\": \"Approved\",\n",
    "}\n",
    "\n",
    "update_response = sagemaker_client.update_model_package(**model_package_update)\n",
    "update_response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create an endpoint config and an endpoint\n",
    "Deploy the endpoint. This might take about 8minutes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![train-assess-tune-register](./images/endpoint.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'endpoint_config_name' (str)\n",
      "Endpoint Config name: fraud-detect-demo-xgboost-post-smote-endpoint-config\n"
     ]
    }
   ],
   "source": [
    "primary_container = {'ModelPackageName': second_model_package['ModelPackageArn']}\n",
    "endpoint_config_name=f'{model_2_name}-endpoint-config'\n",
    "existing_configs = len(sagemaker_client.list_endpoint_configs(NameContains=endpoint_config_name, MaxResults = 30)['EndpointConfigs'])\n",
    "\n",
    "if existing_configs == 0:\n",
    "    create_ep_config_response = sagemaker_client.create_endpoint_config(\n",
    "        EndpointConfigName=endpoint_config_name,\n",
    "        ProductionVariants=[{\n",
    "            'InstanceType': endpoint_instance_type,\n",
    "            'InitialVariantWeight': 1,\n",
    "            'InitialInstanceCount': endpoint_instance_count,\n",
    "            'ModelName': model_2_name,\n",
    "            'VariantName': 'AllTraffic'\n",
    "        }]\n",
    "    )\n",
    "    %store endpoint_config_name\n",
    "    print(f\"Endpoint Config name: {endpoint_config_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'endpoint_name' (str)\n",
      "Endpoint name: fraud-detect-demo-xgboost-post-smote-endpoint\n",
      "Endpoint status: Creating\n",
      "Endpoint status: Creating\n",
      "Endpoint status: Creating\n",
      "Endpoint status: Creating\n",
      "Endpoint status: InService\n"
     ]
    }
   ],
   "source": [
    "existing_endpoints = sagemaker_client.list_endpoints(NameContains=endpoint_name, MaxResults = 30)['Endpoints']\n",
    "if not existing_endpoints:\n",
    "    create_endpoint_response = sagemaker_client.create_endpoint(\n",
    "        EndpointName=endpoint_name,\n",
    "        EndpointConfigName=endpoint_config_name)\n",
    "    %store endpoint_name\n",
    "    print(f\"Endpoint name: {endpoint_name}\")\n",
    "\n",
    "endpoint_info = sagemaker_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "endpoint_status = endpoint_info['EndpointStatus']\n",
    "\n",
    "while endpoint_status == 'Creating':\n",
    "    endpoint_info = sagemaker_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "    endpoint_status = endpoint_info['EndpointStatus']\n",
    "    print('Endpoint status:', endpoint_status)\n",
    "    if endpoint_status == 'Creating':\n",
    "        time.sleep(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='predictor'> </a>\n",
    "\n",
    "### Create a predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------!"
     ]
    }
   ],
   "source": [
    "predictor = sagemaker.predictor.Predictor(\n",
    "    endpoint_name=endpoint_name, sagemaker_session=sagemaker_session\n",
    ")\n",
    "\n",
    "predictor.enable_data_capture()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"data/dataset.csv\")\n",
    "train = dataset.sample(frac=0.8, random_state=0)\n",
    "test = dataset.drop(train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1000 entries, 0 to 4997\n",
      "Data columns (total 48 columns):\n",
      " #   Column                           Non-Null Count  Dtype  \n",
      "---  ------                           --------------  -----  \n",
      " 0   Unnamed: 0                       1000 non-null   int64  \n",
      " 1   policy_id                        1000 non-null   int64  \n",
      " 2   driver_relationship_spouse       1000 non-null   int64  \n",
      " 3   num_insurers_past_5_years        1000 non-null   int64  \n",
      " 4   policy_state_id                  1000 non-null   int64  \n",
      " 5   vehicle_claim                    1000 non-null   float64\n",
      " 6   authorities_contacted_fire       1000 non-null   int64  \n",
      " 7   incident_type_collision          1000 non-null   int64  \n",
      " 8   incident_severity                1000 non-null   int64  \n",
      " 9   injury_claim                     1000 non-null   float64\n",
      " 10  num_vehicles_involved            1000 non-null   int64  \n",
      " 11  policy_liability                 1000 non-null   int64  \n",
      " 12  authorities_contacted_ambulance  1000 non-null   int64  \n",
      " 13  collision_type_side              1000 non-null   int64  \n",
      " 14  collision_type_na                1000 non-null   int64  \n",
      " 15  authorities_contacted_none       1000 non-null   int64  \n",
      " 16  incident_type_theft              1000 non-null   int64  \n",
      " 17  customer_gender_female           1000 non-null   int64  \n",
      " 18  num_injuries                     1000 non-null   int64  \n",
      " 19  authorities_contacted_police     1000 non-null   int64  \n",
      " 20  incident_month                   1000 non-null   int64  \n",
      " 21  collision_type_rear              1000 non-null   int64  \n",
      " 22  customer_age                     1000 non-null   int64  \n",
      " 23  driver_relationship_na           1000 non-null   int64  \n",
      " 24  customer_gender_male             1000 non-null   int64  \n",
      " 25  policy_state_or                  1000 non-null   int64  \n",
      " 26  months_as_customer               1000 non-null   int64  \n",
      " 27  driver_relationship_child        1000 non-null   int64  \n",
      " 28  customer_education               1000 non-null   int64  \n",
      " 29  fraud                            1000 non-null   int64  \n",
      " 30  auto_year                        1000 non-null   int64  \n",
      " 31  policy_state_az                  1000 non-null   int64  \n",
      " 32  incident_dow                     1000 non-null   int64  \n",
      " 33  incident_type_breakin            1000 non-null   int64  \n",
      " 34  incident_day                     1000 non-null   int64  \n",
      " 35  total_claim_amount               1000 non-null   float64\n",
      " 36  policy_state_wa                  1000 non-null   int64  \n",
      " 37  policy_deductable                1000 non-null   int64  \n",
      " 38  driver_relationship_other        1000 non-null   int64  \n",
      " 39  policy_state_nv                  1000 non-null   int64  \n",
      " 40  policy_state_ca                  1000 non-null   int64  \n",
      " 41  num_claims_past_year             1000 non-null   int64  \n",
      " 42  collision_type_front             1000 non-null   int64  \n",
      " 43  incident_hour                    1000 non-null   int64  \n",
      " 44  driver_relationship_self         1000 non-null   int64  \n",
      " 45  police_report_available          1000 non-null   int64  \n",
      " 46  policy_annual_premium            1000 non-null   int64  \n",
      " 47  num_witnesses                    1000 non-null   int64  \n",
      "dtypes: float64(3), int64(45)\n",
      "memory usage: 382.8 KB\n"
     ]
    }
   ],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get sample's claim data from online feature store\n",
    "This will simulate getting data in real-time from a customer's insurance claim submission."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![train-assess-tune-register](./images/endpoint2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sagemaker.session.Session at 0x7f344a4cf450>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featurestore_runtime = boto_session.client(\n",
    "    service_name=\"sagemaker-featurestore-runtime\", region_name=region\n",
    ")\n",
    "\n",
    "feature_store_session = sagemaker.Session(\n",
    "    boto_session=boto_session,\n",
    "    sagemaker_client=sagemaker_client,\n",
    "    sagemaker_featurestore_runtime_client=featurestore_runtime,\n",
    ")\n",
    "feature_store_session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='run-predictions'> </a>\n",
    "\n",
    "## Run Predictions on Multiple Claims\n",
    "\n",
    "[overview](#overview-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probablitity the claim from policy 3521 is fraudulent:, 0.008149230852723122  Time 00.065846\n",
      "Probablitity the claim from policy 4017 is fraudulent:, 0.02115439809858799  Time 00.008960\n",
      "Probablitity the claim from policy 4016 is fraudulent:, 0.007386560086160898  Time 00.008483\n",
      "Probablitity the claim from policy 4106 is fraudulent:, 0.08545010536909103  Time 00.008397\n",
      "Probablitity the claim from policy 500 is fraudulent:, 0.021511288359761238  Time 00.008972\n",
      "Probablitity the claim from policy 3626 is fraudulent:, 0.0041765919886529446  Time 00.008201\n",
      "Probablitity the claim from policy 2591 is fraudulent:, 0.006619956344366074  Time 00.009933\n",
      "Probablitity the claim from policy 491 is fraudulent:, 0.024231871590018272  Time 00.012815\n",
      "Probablitity the claim from policy 1422 is fraudulent:, 0.0077125937677919865  Time 00.009441\n",
      "Probablitity the claim from policy 388 is fraudulent:, 0.004656988196074963  Time 00.010078\n",
      "Probablitity the claim from policy 2675 is fraudulent:, 0.01870565116405487  Time 00.008322\n",
      "Probablitity the claim from policy 2816 is fraudulent:, 0.048799555748701096  Time 00.009457\n",
      "Probablitity the claim from policy 407 is fraudulent:, 0.009340443648397923  Time 00.009258\n",
      "Probablitity the claim from policy 4229 is fraudulent:, 0.010357207618653774  Time 00.009659\n",
      "Probablitity the claim from policy 2758 is fraudulent:, 0.05356866493821144  Time 00.009230\n",
      "Probablitity the claim from policy 1159 is fraudulent:, 0.12324941903352737  Time 00.007555\n",
      "Probablitity the claim from policy 3566 is fraudulent:, 0.0036767234560102224  Time 00.007196\n",
      "Probablitity the claim from policy 2725 is fraudulent:, 0.009351166896522045  Time 00.007730\n",
      "Probablitity the claim from policy 3533 is fraudulent:, 0.04141361638903618  Time 00.009082\n",
      "Probablitity the claim from policy 3065 is fraudulent:, 0.009214479476213455  Time 00.007856\n",
      "Probablitity the claim from policy 2722 is fraudulent:, 0.009768974967300892  Time 00.008469\n",
      "Probablitity the claim from policy 2230 is fraudulent:, 0.008855600841343403  Time 00.007850\n",
      "Probablitity the claim from policy 1972 is fraudulent:, 0.009912672452628613  Time 00.007513\n",
      "Probablitity the claim from policy 1695 is fraudulent:, 0.027075011283159256  Time 00.007516\n",
      "Probablitity the claim from policy 1737 is fraudulent:, 0.008705045096576214  Time 00.007872\n",
      "Probablitity the claim from policy 1046 is fraudulent:, 0.07479269802570343  Time 00.007630\n",
      "Probablitity the claim from policy 3983 is fraudulent:, 0.04739169776439667  Time 00.007532\n",
      "Probablitity the claim from policy 1720 is fraudulent:, 0.04773421213030815  Time 00.007363\n",
      "Probablitity the claim from policy 85 is fraudulent:, 0.01388416439294815  Time 00.009400\n",
      "Probablitity the claim from policy 710 is fraudulent:, 0.024338731542229652  Time 00.008575\n",
      "Probablitity the claim from policy 1648 is fraudulent:, 0.007584175560623407  Time 00.008190\n",
      "Probablitity the claim from policy 782 is fraudulent:, 0.08021265268325806  Time 00.008159\n",
      "Probablitity the claim from policy 710 is fraudulent:, 0.024338731542229652  Time 00.007324\n",
      "Probablitity the claim from policy 3305 is fraudulent:, 0.005354667082428932  Time 00.007624\n",
      "Probablitity the claim from policy 4434 is fraudulent:, 0.004568253643810749  Time 00.010138\n",
      "Probablitity the claim from policy 1314 is fraudulent:, 0.008653921075165272  Time 00.010619\n",
      "Probablitity the claim from policy 2281 is fraudulent:, 0.007138542830944061  Time 00.007076\n",
      "Probablitity the claim from policy 3478 is fraudulent:, 0.007407612632960081  Time 00.008050\n",
      "Probablitity the claim from policy 1696 is fraudulent:, 0.004079286474734545  Time 00.010389\n",
      "Probablitity the claim from policy 820 is fraudulent:, 0.05250218138098717  Time 00.008073\n",
      "Probablitity the claim from policy 4515 is fraudulent:, 0.08296912908554077  Time 00.007450\n",
      "Probablitity the claim from policy 1945 is fraudulent:, 0.19210414588451385  Time 00.007699\n",
      "Probablitity the claim from policy 1983 is fraudulent:, 0.011180935427546501  Time 00.010966\n",
      "Probablitity the claim from policy 3404 is fraudulent:, 0.022667672485113144  Time 00.008045\n",
      "Probablitity the claim from policy 545 is fraudulent:, 0.005891210865229368  Time 00.008066\n",
      "Probablitity the claim from policy 385 is fraudulent:, 0.009320683777332306  Time 00.010512\n",
      "Probablitity the claim from policy 2667 is fraudulent:, 0.012236935086548328  Time 00.008104\n",
      "Probablitity the claim from policy 708 is fraudulent:, 0.061821676790714264  Time 00.007024\n",
      "Probablitity the claim from policy 3471 is fraudulent:, 0.003361239330843091  Time 00.009542\n",
      "Probablitity the claim from policy 4020 is fraudulent:, 0.00476596737280488  Time 00.008128\n",
      "Probablitity the claim from policy 2131 is fraudulent:, 0.026028499007225037  Time 00.010064\n",
      "Probablitity the claim from policy 2071 is fraudulent:, 0.03090195544064045  Time 00.007737\n",
      "Probablitity the claim from policy 2935 is fraudulent:, 0.003780851373448968  Time 00.012526\n",
      "Probablitity the claim from policy 2068 is fraudulent:, 0.010880034416913986  Time 00.007734\n",
      "Probablitity the claim from policy 3871 is fraudulent:, 0.011295495554804802  Time 00.006696\n",
      "Probablitity the claim from policy 1513 is fraudulent:, 0.012472026981413364  Time 00.007395\n",
      "Probablitity the claim from policy 2118 is fraudulent:, 0.020807607099413872  Time 00.008470\n",
      "Probablitity the claim from policy 1401 is fraudulent:, 0.09567189961671829  Time 00.008268\n",
      "Probablitity the claim from policy 858 is fraudulent:, 0.044390950351953506  Time 00.006783\n",
      "Probablitity the claim from policy 4548 is fraudulent:, 0.026028499007225037  Time 00.007257\n",
      "Probablitity the claim from policy 4067 is fraudulent:, 0.05789024010300636  Time 00.006692\n",
      "Probablitity the claim from policy 372 is fraudulent:, 0.08380445092916489  Time 00.007712\n",
      "Probablitity the claim from policy 1759 is fraudulent:, 0.005891210865229368  Time 00.007629\n",
      "Probablitity the claim from policy 3139 is fraudulent:, 0.01947261393070221  Time 00.007209\n",
      "Probablitity the claim from policy 30 is fraudulent:, 0.01388416439294815  Time 00.007085\n",
      "Probablitity the claim from policy 1763 is fraudulent:, 0.06247612088918686  Time 00.009327\n",
      "Probablitity the claim from policy 77 is fraudulent:, 0.010800276882946491  Time 00.006568\n",
      "Probablitity the claim from policy 1692 is fraudulent:, 0.011180935427546501  Time 00.007287\n",
      "Probablitity the claim from policy 43 is fraudulent:, 0.05789024010300636  Time 00.008700\n",
      "Probablitity the claim from policy 496 is fraudulent:, 0.009378279559314251  Time 00.007881\n",
      "Probablitity the claim from policy 2397 is fraudulent:, 0.020998958498239517  Time 00.007825\n",
      "Probablitity the claim from policy 85 is fraudulent:, 0.01388416439294815  Time 00.008061\n",
      "Probablitity the claim from policy 4139 is fraudulent:, 0.03721141070127487  Time 00.007904\n",
      "Probablitity the claim from policy 119 is fraudulent:, 0.15242484211921692  Time 00.007963\n",
      "Probablitity the claim from policy 4322 is fraudulent:, 0.04640308395028114  Time 00.006921\n",
      "Probablitity the claim from policy 2887 is fraudulent:, 0.018655704334378242  Time 00.008404\n",
      "Probablitity the claim from policy 3365 is fraudulent:, 0.003156615886837244  Time 00.008281\n",
      "Probablitity the claim from policy 2040 is fraudulent:, 0.009557968005537987  Time 00.010341\n",
      "Probablitity the claim from policy 3529 is fraudulent:, 0.020366346463561058  Time 00.009258\n",
      "Probablitity the claim from policy 1011 is fraudulent:, 0.2731059193611145  Time 00.007248\n",
      "Probablitity the claim from policy 1551 is fraudulent:, 0.021713923662900925  Time 00.008111\n",
      "Probablitity the claim from policy 2519 is fraudulent:, 0.022667672485113144  Time 00.008691\n",
      "Probablitity the claim from policy 4668 is fraudulent:, 0.009557968005537987  Time 00.007893\n",
      "Probablitity the claim from policy 1159 is fraudulent:, 0.12324941903352737  Time 00.007119\n",
      "Probablitity the claim from policy 3935 is fraudulent:, 0.08801806718111038  Time 00.007910\n",
      "Probablitity the claim from policy 4449 is fraudulent:, 0.006871020421385765  Time 00.007701\n",
      "Probablitity the claim from policy 4378 is fraudulent:, 0.036072392016649246  Time 00.007562\n",
      "Probablitity the claim from policy 3811 is fraudulent:, 0.0031509764958173037  Time 00.006542\n",
      "Probablitity the claim from policy 1422 is fraudulent:, 0.0077125937677919865  Time 00.007272\n",
      "Probablitity the claim from policy 4984 is fraudulent:, 0.003780851373448968  Time 00.007643\n",
      "Probablitity the claim from policy 4185 is fraudulent:, 0.0257854163646698  Time 00.007418\n",
      "Probablitity the claim from policy 500 is fraudulent:, 0.021511288359761238  Time 00.007316\n",
      "Probablitity the claim from policy 3658 is fraudulent:, 0.04290648177266121  Time 00.009234\n",
      "Probablitity the claim from policy 609 is fraudulent:, 0.049933433532714844  Time 00.007281\n",
      "Probablitity the claim from policy 1297 is fraudulent:, 0.053829215466976166  Time 00.007453\n",
      "Probablitity the claim from policy 971 is fraudulent:, 0.004297090228646994  Time 00.008379\n",
      "Probablitity the claim from policy 2161 is fraudulent:, 0.010880034416913986  Time 00.007660\n",
      "Probablitity the claim from policy 4627 is fraudulent:, 0.03360414505004883  Time 00.007583\n",
      "Probablitity the claim from policy 3370 is fraudulent:, 0.011603912338614464  Time 00.009079\n",
      "Probablitity the claim from policy 2131 is fraudulent:, 0.026028499007225037  Time 00.007440\n"
     ]
    }
   ],
   "source": [
    "import datetime as datetime\n",
    "\n",
    "timer = []\n",
    "MAXRECS = 100\n",
    "\n",
    "\n",
    "def barrage_of_inference():\n",
    "    sample_policy_id = int(test.sample(1)[\"policy_id\"])\n",
    "\n",
    "    temp_fg_name = \"fraud-detect-demo-claims\"\n",
    "\n",
    "    claims_response = featurestore_runtime.get_record(\n",
    "        FeatureGroupName=temp_fg_name, RecordIdentifierValueAsString=str(sample_policy_id)\n",
    "    )\n",
    "\n",
    "    if claims_response.get(\"Record\"):\n",
    "        claims_record = claims_response[\"Record\"]\n",
    "        claims_df = pd.DataFrame(claims_record).set_index(\"FeatureName\")\n",
    "    else:\n",
    "        print(\"No Record returned / Record Key  \\n\")\n",
    "\n",
    "    t0 = datetime.datetime.now()\n",
    "\n",
    "    customers_response = featurestore_runtime.get_record(\n",
    "        FeatureGroupName=customers_fg_name, RecordIdentifierValueAsString=str(sample_policy_id)\n",
    "    )\n",
    "\n",
    "    t1 = datetime.datetime.now()\n",
    "\n",
    "    customer_record = customers_response[\"Record\"]\n",
    "    customer_df = pd.DataFrame(customer_record).set_index(\"FeatureName\")\n",
    "\n",
    "    blended_df = pd.concat([claims_df, customer_df]).loc[col_order].drop(\"fraud\")\n",
    "    data_input = \",\".join(blended_df[\"ValueAsString\"])\n",
    "\n",
    "    results = predictor.predict(data_input, initial_args={\"ContentType\": \"text/csv\"})\n",
    "    prediction = json.loads(results)\n",
    "    # print (f'Probablitity the claim from policy {int(sample_policy_id)} is fraudulent:', prediction)\n",
    "\n",
    "    arr = t1 - t0\n",
    "    minutes, seconds = divmod(arr.total_seconds(), 60)\n",
    "\n",
    "    timer.append(seconds)\n",
    "    # print (prediction, \" done in {} \".format(seconds))\n",
    "\n",
    "    return sample_policy_id, prediction, arr\n",
    "\n",
    "\n",
    "for i in range(MAXRECS):\n",
    "    sample_policy_id, prediction, arr = barrage_of_inference()\n",
    "    print(f\"Probablitity the claim from policy {int(sample_policy_id)} is fraudulent:, {prediction}  Time {str(arr).split(':')[2]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: the above \"timer\" records the first call and then subsequent calls to the online Feature Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p95: 0.01051735, p99: 0.013345310000000271, mean: 0.008838819999999999 for 100 distinct feature store gets\n"
     ]
    }
   ],
   "source": [
    "import statistics\n",
    "import numpy as np\n",
    "\n",
    "statistics.mean(timer)\n",
    "\n",
    "\n",
    "arr = np.array(timer)\n",
    "print(\n",
    "    \"p95: {}, p99: {}, mean: {} for {} distinct feature store gets\".format(\n",
    "        np.percentile(arr, 95), np.percentile(arr, 99), np.mean(arr), MAXRECS\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pull customer data from Customers feature group\n",
    "When a customer submits an insurance claim online for instant approval, the insurance company will need to pull customer-specific data from the online feature store to add to the claim data as input for a model prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample a claim from the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Policy ID: 1983\n"
     ]
    }
   ],
   "source": [
    "sample_policy_id = int(test.sample(1)[\"policy_id\"])\n",
    "print(f\"Sample Policy ID: {sample_policy_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ValueAsString</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FeatureName</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>policy_id</th>\n",
       "      <td>1983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>incident_severity</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_vehicles_involved</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_injuries</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_witnesses</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>police_report_available</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>injury_claim</th>\n",
       "      <td>8100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vehicle_claim</th>\n",
       "      <td>14388.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_claim_amount</th>\n",
       "      <td>22488.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>incident_month</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>incident_day</th>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>incident_dow</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>incident_hour</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fraud</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>driver_relationship_self</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>driver_relationship_na</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>driver_relationship_spouse</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>driver_relationship_child</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>driver_relationship_other</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>incident_type_collision</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>incident_type_breakin</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>incident_type_theft</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>collision_type_front</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>collision_type_rear</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>collision_type_side</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>collision_type_na</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>authorities_contacted_police</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>authorities_contacted_none</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>authorities_contacted_ambulance</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>authorities_contacted_fire</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>event_time</th>\n",
       "      <td>1637021306.522106</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     ValueAsString\n",
       "FeatureName                                       \n",
       "policy_id                                     1983\n",
       "incident_severity                                1\n",
       "num_vehicles_involved                            3\n",
       "num_injuries                                     0\n",
       "num_witnesses                                    1\n",
       "police_report_available                          1\n",
       "injury_claim                                8100.0\n",
       "vehicle_claim                              14388.0\n",
       "total_claim_amount                         22488.0\n",
       "incident_month                                   2\n",
       "incident_day                                    19\n",
       "incident_dow                                     1\n",
       "incident_hour                                    5\n",
       "fraud                                            0\n",
       "driver_relationship_self                         1\n",
       "driver_relationship_na                           0\n",
       "driver_relationship_spouse                       0\n",
       "driver_relationship_child                        0\n",
       "driver_relationship_other                        0\n",
       "incident_type_collision                          1\n",
       "incident_type_breakin                            0\n",
       "incident_type_theft                              0\n",
       "collision_type_front                             1\n",
       "collision_type_rear                              0\n",
       "collision_type_side                              0\n",
       "collision_type_na                                0\n",
       "authorities_contacted_police                     1\n",
       "authorities_contacted_none                       0\n",
       "authorities_contacted_ambulance                  0\n",
       "authorities_contacted_fire                       0\n",
       "event_time                       1637021306.522106"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customers_response = featurestore_runtime.get_record(\n",
    "    FeatureGroupName=customers_fg_name, RecordIdentifierValueAsString=str(sample_policy_id)\n",
    ")\n",
    "\n",
    "customer_record = customers_response[\"Record\"]\n",
    "customer_df = pd.DataFrame(customer_record).set_index(\"FeatureName\")\n",
    "\n",
    "\n",
    "claims_response = featurestore_runtime.get_record(\n",
    "    FeatureGroupName=claims_fg_name, RecordIdentifierValueAsString=str(sample_policy_id)\n",
    ")\n",
    "\n",
    "claims_record = claims_response[\"Record\"]\n",
    "claims_df = pd.DataFrame(claims_record).set_index(\"FeatureName\")\n",
    "claims_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Format the datapoint\n",
    "The datapoint must match the exact input format as the model was trained--with all features in the correct order. In this example, the `col_order` variable was saved when you created the train and test datasets earlier in the guide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0,1,0,14388.0,0,1,1,8100.0,3,0,0,0,0,0,0,1,0,1,2,0,55,0,0,0,143,0,3,2008,0,1,0,19,22488.0,0,750,0,0,1,0,1,5,1,1,3000,1'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blended_df = pd.concat([claims_df, customer_df]).loc[col_order].drop(\"fraud\")\n",
    "blended_df\n",
    "data_input = \",\".join(blended_df[\"ValueAsString\"])\n",
    "data_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probablitity the claim from policy 1983 is fraudulent: 0.011180935427546501\n"
     ]
    }
   ],
   "source": [
    "results = predictor.predict(data_input, initial_args={\"ContentType\": \"text/csv\"})\n",
    "prediction = json.loads(results)\n",
    "print(f\"Probablitity the claim from policy {int(sample_policy_id)} is fraudulent:\", prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "<a id='aud-workflow-pipeline'></a>\n",
    "\n",
    "### Next Notebook: [Create and Run an End-to-End Pipeline to Deploy the Model](./07-Pipeline.ipynb)\n",
    "Now that as a Data Scientist, you've manually experimented with each step in our machine learning workflow, you can take certain steps to allow for faster model creation and deployment without sacrificing transparency and tracking via model lineage. In the next section you will create a pipeline which trains a new model on SageMaker, persists the model in SageMaker and then adds the model to the registry and deploys it as a SageMaker hosted endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
