{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4 : Deploy, Run Inference, Interpret Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='overview-4'></a>\n",
    "\n",
    "## [Overview](./0-AutoClaimFraudDetection.ipynb)\n",
    "* [Notebook 0 : Overview, Architecture and Data Exploration](./0-AutoClaimFraudDetection.ipynb)\n",
    "* [Notebook 1: Data Prep, Process, Store Features](./1-data-prep-e2e.ipynb)\n",
    "* [Notebook 2: Train, Check Bias, Tune, Record Lineage, and Register a Model](./2-lineage-train-assess-bias-tune-registry-e2e.ipynb)\n",
    "* [Notebook 3: Mitigate Bias, Train New Model, Store in Registry](./3-mitigate-bias-train-model2-registry-e2e.ipynb)\n",
    "* **[Notebook 4: Deploy Model, Run Predictions](./4-deploy-run-inference-e2e.ipynb)**\n",
    "  * **[Architecture](#deploy)**\n",
    "  * **[Deploy an approved model and Run Inference via Feature Store](#deploy-model)**\n",
    "  * **[Create a Predictor](#predictor)**\n",
    "  * **[Run Predictions from Online FeatureStore](#run-predictions)**\n",
    "* [Notebook 5 : Create and Run an End-to-End Pipeline to Deploy the Model](./5-pipeline-e2e.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section of the end to end use case, we will deploy the mitigated model that is the end-product of this fraud detection use-case. We will show how to run inference and also how to use Clarify to interpret or \"explain\" the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install required and/or update third-party libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/secretstorage/dhcrypto.py:16: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "/opt/conda/lib/python3.7/site-packages/secretstorage/util.py:25: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "/opt/conda/lib/python3.7/site-packages/secretstorage/dhcrypto.py:16: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "/opt/conda/lib/python3.7/site-packages/secretstorage/util.py:25: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install -Uq pip\n",
    "!python -m pip install -q awswrangler imbalanced-learn sagemaker boto3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load stored variables\n",
    "Run the cell below to load any prevously created variables. You should see a print-out of the existing variables. If you don't see anything you may need to create them again or it may be your first time running this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored variables and their in-db values:\n",
      "bucket                             -> 'sagemaker-us-east-1-875692608981'\n",
      "claims_fg_name                     -> 'fraud-detect-demo-claims'\n",
      "claims_preprocessed                ->       policy_id  incident_severity  num_vehicles_i\n",
      "claims_table                       -> 'fraud-detect-demo-claims-1636518800'\n",
      "clarify_expl_job_name              -> 'Clarify-Explainability-2021-11-10-14-35-21-747'\n",
      "col_order                          -> ['fraud', 'authorities_contacted_none', 'policy_li\n",
      "customers_fg_name                  -> 'fraud-detect-demo-customers'\n",
      "customers_preprocessed             ->       policy_id  customer_age  customer_education \n",
      "customers_table                    -> 'fraud-detect-demo-customers-1636518803'\n",
      "database_name                      -> 'sagemaker_featurestore'\n",
      "hyperparameters                    -> {'max_depth': '3', 'eta': '0.2', 'objective': 'bin\n",
      "model_1_name                       -> 'fraud-detect-demo-xgboost-pre-smote'\n",
      "model_2_name                       -> 'fraud-detect-demo-xgboost-post-smote'\n",
      "mpg_name                           -> 'fraud-detect-demo'\n",
      "prefix                             -> 'fraud-detect-demo'\n",
      "test_data_uri                      -> 's3://sagemaker-us-east-1-875692608981/fraud-detec\n",
      "train_data_uri                     -> 's3://sagemaker-us-east-1-875692608981/fraud-detec\n",
      "training_job_1_name                -> 'sagemaker-xgboost-2021-11-10-04-56-34-757'\n",
      "training_job_2_name                -> 'sagemaker-xgboost-2021-11-10-14-28-13-883'\n"
     ]
    }
   ],
   "source": [
    "%store -r\n",
    "%store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color='red'>Important</font>: You must have run the previous sequential notebooks to retrieve variables using the StoreMagic command.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "import boto3\n",
    "import sagemaker\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import awswrangler as wr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set region, boto3 and SageMaker SDK variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using AWS Region: us-east-1\n"
     ]
    }
   ],
   "source": [
    "# You can change this to a region of your choice\n",
    "import sagemaker\n",
    "\n",
    "region = sagemaker.Session().boto_region_name\n",
    "print(\"Using AWS Region: {}\".format(region))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "boto3.setup_default_session(region_name=region)\n",
    "\n",
    "boto_session = boto3.Session(region_name=region)\n",
    "\n",
    "s3_client = boto3.client(\"s3\", region_name=region)\n",
    "\n",
    "sagemaker_boto_client = boto_session.client(\"sagemaker\")\n",
    "\n",
    "sagemaker_session = sagemaker.session.Session(\n",
    "    boto_session=boto_session, sagemaker_client=sagemaker_boto_client\n",
    ")\n",
    "\n",
    "sagemaker_role = sagemaker.get_execution_role()\n",
    "\n",
    "account_id = boto3.client(\"sts\").get_caller_identity()[\"Account\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables used for parameterizing the notebook run\n",
    "endpoint_name = f\"{model_2_name}-endpoint\"\n",
    "endpoint_instance_count = 1\n",
    "endpoint_instance_type = \"ml.m4.xlarge\"\n",
    "\n",
    "predictor_instance_count = 1\n",
    "predictor_instance_type = \"ml.c5.xlarge\"\n",
    "batch_transform_instance_count = 1\n",
    "batch_transform_instance_type = \"ml.c5.xlarge\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id ='deploy'> </a>\n",
    "\n",
    "## Architecture for this ML Lifecycle Stage : Train, Check Bias, Tune, Record Lineage, Register Model\n",
    "[overview](#overview-4)\n",
    "\n",
    "![train-assess-tune-register](./images/e2e-3-pipeline-v3b.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id ='deploy-model'></a>\n",
    "\n",
    "## Deploy an approved model and make prediction via Feature Store\n",
    "\n",
    "[overview](#overview-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Approve the second model\n",
    "In the real-life MLOps lifecycle, a model package gets approved after evaluation by data scientists, subject matter experts and auditors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ModelPackageArn': 'arn:aws:sagemaker:us-east-1:875692608981:model-package/fraud-detect-demo/1',\n",
       " 'ResponseMetadata': {'RequestId': '5b4b6e4f-9aee-4d24-846d-1fd83b799ad3',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '5b4b6e4f-9aee-4d24-846d-1fd83b799ad3',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '96',\n",
       "   'date': 'Thu, 11 Nov 2021 00:04:32 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_model_package = sagemaker_boto_client.list_model_packages(ModelPackageGroupName=mpg_name)[\"ModelPackageSummaryList\"][0]\n",
    "model_package_update = {\n",
    "    \"ModelPackageArn\": second_model_package[\"ModelPackageArn\"],\n",
    "    \"ModelApprovalStatus\": \"Approved\",\n",
    "}\n",
    "\n",
    "update_response = sagemaker_boto_client.update_model_package(**model_package_update)\n",
    "update_response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create an endpoint config and an endpoint\n",
    "Deploy the endpoint. This might take about 8minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'endpoint_config_name' (str)\n",
      "Endpoint Config name: fraud-detect-demo-xgboost-post-smote-endpoint-config\n"
     ]
    }
   ],
   "source": [
    "primary_container = {'ModelPackageName': second_model_package['ModelPackageArn']}\n",
    "endpoint_config_name=f'{model_2_name}-endpoint-config'\n",
    "existing_configs = len(sagemaker_boto_client.list_endpoint_configs(NameContains=endpoint_config_name, MaxResults = 30)['EndpointConfigs'])\n",
    "\n",
    "if existing_configs == 0:\n",
    "    create_ep_config_response = sagemaker_boto_client.create_endpoint_config(\n",
    "        EndpointConfigName=endpoint_config_name,\n",
    "        ProductionVariants=[{\n",
    "            'InstanceType': endpoint_instance_type,\n",
    "            'InitialVariantWeight': 1,\n",
    "            'InitialInstanceCount': endpoint_instance_count,\n",
    "            'ModelName': model_2_name,\n",
    "            'VariantName': 'AllTraffic'\n",
    "        }]\n",
    "    )\n",
    "    %store endpoint_config_name\n",
    "    print(f\"Endpoint Config name: {endpoint_config_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'endpoint_name' (str)\n",
      "Endpoint name: fraud-detect-demo-xgboost-post-smote-endpoint\n",
      "Endpoint status: Creating\n",
      "Endpoint status: Creating\n",
      "Endpoint status: Creating\n",
      "Endpoint status: InService\n"
     ]
    }
   ],
   "source": [
    "existing_endpoints = sagemaker_boto_client.list_endpoints(NameContains=endpoint_name, MaxResults = 30)['Endpoints']\n",
    "if not existing_endpoints:\n",
    "    create_endpoint_response = sagemaker_boto_client.create_endpoint(\n",
    "        EndpointName=endpoint_name,\n",
    "        EndpointConfigName=endpoint_config_name)\n",
    "    %store endpoint_name\n",
    "    print(f\"Endpoint name: {endpoint_name}\")\n",
    "\n",
    "endpoint_info = sagemaker_boto_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "endpoint_status = endpoint_info['EndpointStatus']\n",
    "\n",
    "while endpoint_status == 'Creating':\n",
    "    endpoint_info = sagemaker_boto_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "    endpoint_status = endpoint_info['EndpointStatus']\n",
    "    print('Endpoint status:', endpoint_status)\n",
    "    if endpoint_status == 'Creating':\n",
    "        time.sleep(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='predictor'> </a>\n",
    "\n",
    "### Create a predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------!"
     ]
    }
   ],
   "source": [
    "predictor = sagemaker.predictor.Predictor(\n",
    "    endpoint_name=endpoint_name, sagemaker_session=sagemaker_session\n",
    ")\n",
    "\n",
    "predictor.enable_data_capture()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Policy ID: 3472\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv(\"data/dataset.csv\")\n",
    "train = dataset.sample(frac=0.8, random_state=0)\n",
    "test = dataset.drop(train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1000 entries, 0 to 4997\n",
      "Data columns (total 48 columns):\n",
      " #   Column                           Non-Null Count  Dtype  \n",
      "---  ------                           --------------  -----  \n",
      " 0   Unnamed: 0                       1000 non-null   int64  \n",
      " 1   policy_id                        1000 non-null   int64  \n",
      " 2   authorities_contacted_none       1000 non-null   int64  \n",
      " 3   policy_liability                 1000 non-null   int64  \n",
      " 4   customer_gender_female           1000 non-null   int64  \n",
      " 5   fraud                            1000 non-null   int64  \n",
      " 6   incident_severity                1000 non-null   int64  \n",
      " 7   total_claim_amount               1000 non-null   float64\n",
      " 8   driver_relationship_child        1000 non-null   int64  \n",
      " 9   policy_state_az                  1000 non-null   int64  \n",
      " 10  police_report_available          1000 non-null   int64  \n",
      " 11  driver_relationship_self         1000 non-null   int64  \n",
      " 12  authorities_contacted_police     1000 non-null   int64  \n",
      " 13  num_witnesses                    1000 non-null   int64  \n",
      " 14  collision_type_front             1000 non-null   int64  \n",
      " 15  vehicle_claim                    1000 non-null   float64\n",
      " 16  incident_day                     1000 non-null   int64  \n",
      " 17  incident_type_breakin            1000 non-null   int64  \n",
      " 18  policy_state_nv                  1000 non-null   int64  \n",
      " 19  policy_state_or                  1000 non-null   int64  \n",
      " 20  injury_claim                     1000 non-null   float64\n",
      " 21  num_vehicles_involved            1000 non-null   int64  \n",
      " 22  incident_type_collision          1000 non-null   int64  \n",
      " 23  policy_state_ca                  1000 non-null   int64  \n",
      " 24  num_claims_past_year             1000 non-null   int64  \n",
      " 25  incident_hour                    1000 non-null   int64  \n",
      " 26  collision_type_side              1000 non-null   int64  \n",
      " 27  incident_month                   1000 non-null   int64  \n",
      " 28  policy_annual_premium            1000 non-null   int64  \n",
      " 29  months_as_customer               1000 non-null   int64  \n",
      " 30  num_insurers_past_5_years        1000 non-null   int64  \n",
      " 31  policy_deductable                1000 non-null   int64  \n",
      " 32  incident_type_theft              1000 non-null   int64  \n",
      " 33  num_injuries                     1000 non-null   int64  \n",
      " 34  customer_gender_male             1000 non-null   int64  \n",
      " 35  authorities_contacted_ambulance  1000 non-null   int64  \n",
      " 36  customer_education               1000 non-null   int64  \n",
      " 37  driver_relationship_spouse       1000 non-null   int64  \n",
      " 38  policy_state_wa                  1000 non-null   int64  \n",
      " 39  collision_type_rear              1000 non-null   int64  \n",
      " 40  incident_dow                     1000 non-null   int64  \n",
      " 41  policy_state_id                  1000 non-null   int64  \n",
      " 42  auto_year                        1000 non-null   int64  \n",
      " 43  driver_relationship_na           1000 non-null   int64  \n",
      " 44  customer_age                     1000 non-null   int64  \n",
      " 45  authorities_contacted_fire       1000 non-null   int64  \n",
      " 46  driver_relationship_other        1000 non-null   int64  \n",
      " 47  collision_type_na                1000 non-null   int64  \n",
      "dtypes: float64(3), int64(45)\n",
      "memory usage: 382.8 KB\n"
     ]
    }
   ],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get sample's claim data from online feature store\n",
    "This will simulate getting data in real-time from a customer's insurance claim submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sagemaker.session.Session at 0x7fcbedf7cd10>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featurestore_runtime = boto_session.client(\n",
    "    service_name=\"sagemaker-featurestore-runtime\", region_name=region\n",
    ")\n",
    "\n",
    "feature_store_session = sagemaker.Session(\n",
    "    boto_session=boto_session,\n",
    "    sagemaker_client=sagemaker_boto_client,\n",
    "    sagemaker_featurestore_runtime_client=featurestore_runtime,\n",
    ")\n",
    "feature_store_session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='run-predictions'> </a>\n",
    "\n",
    "## Run Predictions on Multiple Claims\n",
    "\n",
    "[overview](#overview-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probablitity the claim from policy 1774 is fraudulent:, 0.021375291049480438  Time 00.016930\n",
      "Probablitity the claim from policy 4062 is fraudulent:, 0.011197041720151901  Time 00.015673\n",
      "Probablitity the claim from policy 2471 is fraudulent:, 0.020389219745993614  Time 00.011314\n",
      "Probablitity the claim from policy 645 is fraudulent:, 0.009047198109328747  Time 00.014818\n",
      "Probablitity the claim from policy 1655 is fraudulent:, 0.027866942808032036  Time 00.013072\n",
      "Probablitity the claim from policy 1384 is fraudulent:, 0.01015917956829071  Time 00.011230\n",
      "Probablitity the claim from policy 1034 is fraudulent:, 0.004062822554260492  Time 00.011439\n",
      "Probablitity the claim from policy 2462 is fraudulent:, 0.0034130578860640526  Time 00.009626\n",
      "Probablitity the claim from policy 3955 is fraudulent:, 0.00377092557027936  Time 00.012827\n",
      "Probablitity the claim from policy 1532 is fraudulent:, 0.04017901048064232  Time 00.016592\n",
      "Probablitity the claim from policy 311 is fraudulent:, 0.011240511201322079  Time 00.011042\n",
      "Probablitity the claim from policy 130 is fraudulent:, 0.005029096268117428  Time 00.013274\n",
      "Probablitity the claim from policy 549 is fraudulent:, 0.07903976738452911  Time 00.012296\n",
      "Probablitity the claim from policy 4738 is fraudulent:, 0.00435194605961442  Time 00.011233\n",
      "Probablitity the claim from policy 1076 is fraudulent:, 0.025259532034397125  Time 00.012621\n",
      "Probablitity the claim from policy 4348 is fraudulent:, 0.045145824551582336  Time 00.044553\n",
      "Probablitity the claim from policy 492 is fraudulent:, 0.0037522593047469854  Time 00.015000\n",
      "Probablitity the claim from policy 3955 is fraudulent:, 0.00377092557027936  Time 00.013601\n",
      "Probablitity the claim from policy 3110 is fraudulent:, 0.00929353479295969  Time 00.010500\n",
      "Probablitity the claim from policy 4002 is fraudulent:, 0.015140630304813385  Time 00.010554\n",
      "Probablitity the claim from policy 238 is fraudulent:, 0.010168131440877914  Time 00.017584\n",
      "Probablitity the claim from policy 3301 is fraudulent:, 0.009019686840474606  Time 00.015181\n",
      "Probablitity the claim from policy 2414 is fraudulent:, 0.007025224156677723  Time 00.013219\n",
      "Probablitity the claim from policy 1409 is fraudulent:, 0.1259615272283554  Time 00.012941\n",
      "Probablitity the claim from policy 1839 is fraudulent:, 0.02993197552859783  Time 00.011141\n",
      "Probablitity the claim from policy 2269 is fraudulent:, 0.04305557906627655  Time 00.010383\n",
      "Probablitity the claim from policy 1130 is fraudulent:, 0.07689766585826874  Time 00.009860\n",
      "Probablitity the claim from policy 319 is fraudulent:, 0.11289254575967789  Time 00.010451\n",
      "Probablitity the claim from policy 3301 is fraudulent:, 0.009019686840474606  Time 00.008541\n",
      "Probablitity the claim from policy 4704 is fraudulent:, 0.004286793060600758  Time 00.008325\n",
      "Probablitity the claim from policy 4938 is fraudulent:, 0.030031615868210793  Time 00.010616\n",
      "Probablitity the claim from policy 4632 is fraudulent:, 0.01791936717927456  Time 00.014973\n",
      "Probablitity the claim from policy 1058 is fraudulent:, 0.026371905580163002  Time 00.012270\n",
      "Probablitity the claim from policy 2979 is fraudulent:, 0.02559380978345871  Time 00.009962\n",
      "Probablitity the claim from policy 3652 is fraudulent:, 0.1092500314116478  Time 00.011170\n",
      "Probablitity the claim from policy 246 is fraudulent:, 0.17889781296253204  Time 00.013039\n",
      "Probablitity the claim from policy 1384 is fraudulent:, 0.01015917956829071  Time 00.009693\n",
      "Probablitity the claim from policy 1588 is fraudulent:, 0.023666825145483017  Time 00.010477\n",
      "Probablitity the claim from policy 4759 is fraudulent:, 0.02566639706492424  Time 00.008744\n",
      "Probablitity the claim from policy 3312 is fraudulent:, 0.009919456206262112  Time 00.009598\n",
      "Probablitity the claim from policy 7 is fraudulent:, 0.026425231248140335  Time 00.010424\n",
      "Probablitity the claim from policy 4936 is fraudulent:, 0.08404099941253662  Time 00.013148\n",
      "Probablitity the claim from policy 3690 is fraudulent:, 0.005029096268117428  Time 00.014589\n",
      "Probablitity the claim from policy 4141 is fraudulent:, 0.030442731454968452  Time 00.011444\n",
      "Probablitity the claim from policy 567 is fraudulent:, 0.026371905580163002  Time 00.010116\n",
      "Probablitity the claim from policy 4665 is fraudulent:, 0.17095644772052765  Time 00.010572\n",
      "Probablitity the claim from policy 130 is fraudulent:, 0.005029096268117428  Time 00.009606\n",
      "Probablitity the claim from policy 2557 is fraudulent:, 0.005029096268117428  Time 00.009778\n",
      "Probablitity the claim from policy 3653 is fraudulent:, 0.006829629186540842  Time 00.018356\n",
      "Probablitity the claim from policy 2011 is fraudulent:, 0.011158415116369724  Time 00.011220\n",
      "Probablitity the claim from policy 4906 is fraudulent:, 0.00377092557027936  Time 00.011153\n",
      "Probablitity the claim from policy 1735 is fraudulent:, 0.04473590478301048  Time 00.010764\n",
      "Probablitity the claim from policy 535 is fraudulent:, 0.004286793060600758  Time 00.009947\n",
      "Probablitity the claim from policy 1655 is fraudulent:, 0.027866942808032036  Time 00.009199\n",
      "Probablitity the claim from policy 380 is fraudulent:, 0.01028045266866684  Time 00.010846\n",
      "Probablitity the claim from policy 1644 is fraudulent:, 0.004042717162519693  Time 00.013380\n",
      "Probablitity the claim from policy 447 is fraudulent:, 0.025259532034397125  Time 00.009420\n",
      "Probablitity the claim from policy 2571 is fraudulent:, 0.007827875204384327  Time 00.010163\n",
      "Probablitity the claim from policy 3110 is fraudulent:, 0.00929353479295969  Time 00.009958\n",
      "Probablitity the claim from policy 4463 is fraudulent:, 0.0705893412232399  Time 00.011973\n",
      "Probablitity the claim from policy 260 is fraudulent:, 0.011496596038341522  Time 00.009957\n",
      "Probablitity the claim from policy 645 is fraudulent:, 0.009047198109328747  Time 00.008746\n",
      "Probablitity the claim from policy 2715 is fraudulent:, 0.00377092557027936  Time 00.009432\n",
      "Probablitity the claim from policy 2651 is fraudulent:, 0.029090117663145065  Time 00.008923\n",
      "Probablitity the claim from policy 2680 is fraudulent:, 0.022213084623217583  Time 00.010832\n",
      "Probablitity the claim from policy 467 is fraudulent:, 0.11621838808059692  Time 00.012124\n",
      "Probablitity the claim from policy 4932 is fraudulent:, 0.01886870712041855  Time 00.014267\n",
      "Probablitity the claim from policy 4411 is fraudulent:, 0.004286793060600758  Time 00.010772\n",
      "Probablitity the claim from policy 2240 is fraudulent:, 0.030031615868210793  Time 00.010207\n",
      "Probablitity the claim from policy 1067 is fraudulent:, 0.030031615868210793  Time 00.011590\n",
      "Probablitity the claim from policy 3086 is fraudulent:, 0.007039298769086599  Time 00.009194\n",
      "Probablitity the claim from policy 3830 is fraudulent:, 0.008585697039961815  Time 00.010712\n",
      "Probablitity the claim from policy 1103 is fraudulent:, 0.02323850989341736  Time 00.009872\n",
      "Probablitity the claim from policy 88 is fraudulent:, 0.004286793060600758  Time 00.015259\n",
      "Probablitity the claim from policy 841 is fraudulent:, 0.03966863825917244  Time 00.010235\n",
      "Probablitity the claim from policy 4250 is fraudulent:, 0.02276472933590412  Time 00.009791\n",
      "Probablitity the claim from policy 1820 is fraudulent:, 0.009919456206262112  Time 00.010428\n",
      "Probablitity the claim from policy 3677 is fraudulent:, 0.015390547923743725  Time 00.011728\n",
      "Probablitity the claim from policy 345 is fraudulent:, 0.02559380978345871  Time 00.012343\n",
      "Probablitity the claim from policy 3707 is fraudulent:, 0.03697461634874344  Time 00.010931\n",
      "Probablitity the claim from policy 2711 is fraudulent:, 0.12954799830913544  Time 00.008791\n",
      "Probablitity the claim from policy 1275 is fraudulent:, 0.056474197655916214  Time 00.011574\n",
      "Probablitity the claim from policy 415 is fraudulent:, 0.02530789002776146  Time 00.010359\n",
      "Probablitity the claim from policy 3677 is fraudulent:, 0.015390547923743725  Time 00.011531\n",
      "Probablitity the claim from policy 1543 is fraudulent:, 0.023789595812559128  Time 00.015180\n",
      "Probablitity the claim from policy 238 is fraudulent:, 0.010168131440877914  Time 00.011002\n",
      "Probablitity the claim from policy 1655 is fraudulent:, 0.027866942808032036  Time 00.009689\n",
      "Probablitity the claim from policy 4565 is fraudulent:, 0.02323850989341736  Time 00.010694\n",
      "Probablitity the claim from policy 88 is fraudulent:, 0.004286793060600758  Time 00.010484\n",
      "Probablitity the claim from policy 4277 is fraudulent:, 0.00377092557027936  Time 00.011161\n",
      "Probablitity the claim from policy 4552 is fraudulent:, 0.014459964819252491  Time 00.014376\n",
      "Probablitity the claim from policy 2749 is fraudulent:, 0.0160088911652565  Time 00.010038\n",
      "Probablitity the claim from policy 161 is fraudulent:, 0.016230463981628418  Time 00.008953\n",
      "Probablitity the claim from policy 3619 is fraudulent:, 0.01126409787684679  Time 00.010732\n",
      "Probablitity the claim from policy 4432 is fraudulent:, 0.017699601128697395  Time 00.009343\n",
      "Probablitity the claim from policy 1051 is fraudulent:, 0.015390547923743725  Time 00.010879\n",
      "Probablitity the claim from policy 2769 is fraudulent:, 0.011266939342021942  Time 00.009677\n",
      "Probablitity the claim from policy 1382 is fraudulent:, 0.004552371799945831  Time 00.010372\n",
      "Probablitity the claim from policy 1932 is fraudulent:, 0.006829629186540842  Time 00.010956\n",
      "Probablitity the claim from policy 2610 is fraudulent:, 0.021883541718125343  Time 00.009498\n"
     ]
    }
   ],
   "source": [
    "import datetime as datetime\n",
    "\n",
    "timer = []\n",
    "MAXRECS = 100\n",
    "\n",
    "\n",
    "def barrage_of_inference():\n",
    "    sample_policy_id = int(test.sample(1)[\"policy_id\"])\n",
    "\n",
    "    temp_fg_name = \"fraud-detect-demo-claims\"\n",
    "\n",
    "    claims_response = featurestore_runtime.get_record(\n",
    "        FeatureGroupName=temp_fg_name, RecordIdentifierValueAsString=str(sample_policy_id)\n",
    "    )\n",
    "\n",
    "    if claims_response.get(\"Record\"):\n",
    "        claims_record = claims_response[\"Record\"]\n",
    "        claims_df = pd.DataFrame(claims_record).set_index(\"FeatureName\")\n",
    "    else:\n",
    "        print(\"No Record returned / Record Key  \\n\")\n",
    "\n",
    "    t0 = datetime.datetime.now()\n",
    "\n",
    "    customers_response = featurestore_runtime.get_record(\n",
    "        FeatureGroupName=customers_fg_name, RecordIdentifierValueAsString=str(sample_policy_id)\n",
    "    )\n",
    "\n",
    "    t1 = datetime.datetime.now()\n",
    "\n",
    "    customer_record = customers_response[\"Record\"]\n",
    "    customer_df = pd.DataFrame(customer_record).set_index(\"FeatureName\")\n",
    "\n",
    "    blended_df = pd.concat([claims_df, customer_df]).loc[col_order].drop(\"fraud\")\n",
    "    data_input = \",\".join(blended_df[\"ValueAsString\"])\n",
    "\n",
    "    results = predictor.predict(data_input, initial_args={\"ContentType\": \"text/csv\"})\n",
    "    prediction = json.loads(results)\n",
    "    # print (f'Probablitity the claim from policy {int(sample_policy_id)} is fraudulent:', prediction)\n",
    "\n",
    "    arr = t1 - t0\n",
    "    minutes, seconds = divmod(arr.total_seconds(), 60)\n",
    "\n",
    "    timer.append(seconds)\n",
    "    # print (prediction, \" done in {} \".format(seconds))\n",
    "\n",
    "    return sample_policy_id, prediction, arr\n",
    "\n",
    "\n",
    "for i in range(MAXRECS):\n",
    "    sample_policy_id, prediction, arr = barrage_of_inference()\n",
    "    print(f\"Probablitity the claim from policy {int(sample_policy_id)} is fraudulent:, {prediction}  Time {str(arr).split(':')[2]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: the above \"timer\" records the first call and then subsequent calls to the online Feature Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p95: 0.015718949999999995, p99: 0.018617970000000136, mean: 0.011750509999999999 for 100 distinct feature store gets\n"
     ]
    }
   ],
   "source": [
    "import statistics\n",
    "import numpy as np\n",
    "\n",
    "statistics.mean(timer)\n",
    "\n",
    "\n",
    "arr = np.array(timer)\n",
    "print(\n",
    "    \"p95: {}, p99: {}, mean: {} for {} distinct feature store gets\".format(\n",
    "        np.percentile(arr, 95), np.percentile(arr, 99), np.mean(arr), MAXRECS\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pull customer data from Customers feature group\n",
    "When a customer submits an insurance claim online for instant approval, the insurance company will need to pull customer-specific data from the online feature store to add to the claim data as input for a model prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample a claim from the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Policy ID: 3439\n"
     ]
    }
   ],
   "source": [
    "sample_policy_id = int(test.sample(1)[\"policy_id\"])\n",
    "print(f\"Sample Policy ID: {sample_policy_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ValueAsString</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FeatureName</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>policy_id</th>\n",
       "      <td>3439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>incident_severity</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_vehicles_involved</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_injuries</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_witnesses</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>police_report_available</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>injury_claim</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vehicle_claim</th>\n",
       "      <td>12000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_claim_amount</th>\n",
       "      <td>12000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>incident_month</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>incident_day</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>incident_dow</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>incident_hour</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fraud</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>driver_relationship_self</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>driver_relationship_na</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>driver_relationship_spouse</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>driver_relationship_child</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>driver_relationship_other</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>incident_type_collision</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>incident_type_breakin</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>incident_type_theft</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>collision_type_front</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>collision_type_rear</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>collision_type_side</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>collision_type_na</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>authorities_contacted_police</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>authorities_contacted_none</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>authorities_contacted_fire</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>authorities_contacted_ambulance</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>event_time</th>\n",
       "      <td>1636518789.219854</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     ValueAsString\n",
       "FeatureName                                       \n",
       "policy_id                                     3439\n",
       "incident_severity                                0\n",
       "num_vehicles_involved                            1\n",
       "num_injuries                                     0\n",
       "num_witnesses                                    0\n",
       "police_report_available                          0\n",
       "injury_claim                                   0.0\n",
       "vehicle_claim                              12000.0\n",
       "total_claim_amount                         12000.0\n",
       "incident_month                                   2\n",
       "incident_day                                    10\n",
       "incident_dow                                     6\n",
       "incident_hour                                   12\n",
       "fraud                                            0\n",
       "driver_relationship_self                         0\n",
       "driver_relationship_na                           0\n",
       "driver_relationship_spouse                       0\n",
       "driver_relationship_child                        1\n",
       "driver_relationship_other                        0\n",
       "incident_type_collision                          1\n",
       "incident_type_breakin                            0\n",
       "incident_type_theft                              0\n",
       "collision_type_front                             0\n",
       "collision_type_rear                              1\n",
       "collision_type_side                              0\n",
       "collision_type_na                                0\n",
       "authorities_contacted_police                     0\n",
       "authorities_contacted_none                       1\n",
       "authorities_contacted_fire                       0\n",
       "authorities_contacted_ambulance                  0\n",
       "event_time                       1636518789.219854"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customers_response = featurestore_runtime.get_record(\n",
    "    FeatureGroupName=customers_fg_name, RecordIdentifierValueAsString=str(sample_policy_id)\n",
    ")\n",
    "\n",
    "customer_record = customers_response[\"Record\"]\n",
    "customer_df = pd.DataFrame(customer_record).set_index(\"FeatureName\")\n",
    "\n",
    "\n",
    "claims_response = featurestore_runtime.get_record(\n",
    "    FeatureGroupName=claims_fg_name, RecordIdentifierValueAsString=str(sample_policy_id)\n",
    ")\n",
    "\n",
    "claims_record = claims_response[\"Record\"]\n",
    "claims_df = pd.DataFrame(claims_record).set_index(\"FeatureName\")\n",
    "claims_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Format the datapoint\n",
    "The datapoint must match the exact input format as the model was trained--with all features in the correct order. In this example, the `col_order` variable was saved when you created the train and test datasets earlier in the guide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1,1,0,0,12000.0,1,0,0,0,0,0,0,12000.0,10,0,0,0,0.0,1,1,1,4,12,0,2,3000,27,2,750,0,0,1,0,3,0,0,1,6,0,2020,0,24,0,0,0'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blended_df = pd.concat([claims_df, customer_df]).loc[col_order].drop(\"fraud\")\n",
    "blended_df\n",
    "data_input = \",\".join(blended_df[\"ValueAsString\"])\n",
    "data_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probablitity the claim from policy 3439 is fraudulent: 0.15065261721611023\n"
     ]
    }
   ],
   "source": [
    "results = predictor.predict(data_input, initial_args={\"ContentType\": \"text/csv\"})\n",
    "prediction = json.loads(results)\n",
    "print(f\"Probablitity the claim from policy {int(sample_policy_id)} is fraudulent:\", prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "<a id='aud-workflow-pipeline'></a>\n",
    "\n",
    "### Next Notebook: [Create and Run an End-to-End Pipeline to Deploy the Model](./07-Pipeline.ipynb)\n",
    "Now that as a Data Scientist, you've manually experimented with each step in our machine learning workflow, you can take certain steps to allow for faster model creation and deployment without sacrificing transparency and tracking via model lineage. In the next section you will create a pipeline which trains a new model on SageMaker, persists the model in SageMaker and then adds the model to the registry and deploys it as a SageMaker hosted endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
